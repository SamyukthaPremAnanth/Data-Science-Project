{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training and testing using LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamyukthaPremAnanth/admire-yourself/blob/main/training_and_testing_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H2MbrXgCHMx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peE5gl1j2859"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import glob\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRuJUGEr3Haa"
      },
      "source": [
        "BASE_PATH=\"drive/MyDrive/data/UCF-101\"\n",
        "VIDEOS_PATH=os.path.join(BASE_PATH,\"**\",\"*.avi\")\n",
        "SEQUENCE_LENGTH=40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6VZfAxJMsSM",
        "outputId": "378bfb2f-4c4a-4767-bbeb-c4b0f47e6693"
      },
      "source": [
        "def frame_generator():\n",
        "  video_paths=tf.io.gfile.glob(VIDEOS_PATH)\n",
        "  np.random.shuffle(video_paths)\n",
        "  for video_path in video_paths:\n",
        "    frames=[]\n",
        "    cap=cv2.VideoCapture(video_path)\n",
        "    num_frames=int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    sample_every_frame=max(1,num_frames // SEQUENCE_LENGTH)\n",
        "    current_frame=0\n",
        "\n",
        "    label=os.path.basename(os.path.dirname(video_path))\n",
        "\n",
        "    max_images=SEQUENCE_LENGTH\n",
        "    while True:\n",
        "      success , frame=cap.read()\n",
        "      if not success:\n",
        "        break\n",
        "\n",
        "      if current_frame % sample_every_frame ==0:\n",
        "        frame=frame[:,:,::-1]\n",
        "        img=tf.image.resize(frame,(299,299))\n",
        "        img=tf.keras.applications.inception_v3.preprocess_input(\n",
        "            img)\n",
        "        max_images -=1\n",
        "        yield img,video_path\n",
        "      \n",
        "      if max_images==0:\n",
        "        break\n",
        "      current_frame +=1\n",
        "\n",
        "\n",
        "dataset=tf.data.Dataset.from_generator(frame_generator,\n",
        "           output_types=(tf.float32,tf.string),\n",
        "           output_shapes=((299,299,3),()))\n",
        "dataset=dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((None, 299, 299, 3), (None,)), types: (tf.float32, tf.string)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glyqmxgSMw21",
        "outputId": "0a6fd0b9-4ff6-4aa0-caac-82557f1d0ff3"
      },
      "source": [
        "inception_v3=tf.keras.applications.InceptionV3(include_top=False, weights=\"imagenet\")\n",
        "X=inception_v3.output\n",
        "pooling_output=tf.keras.layers.GlobalAveragePooling2D()(X)\n",
        "feature_extraction_model=tf.keras.Model(inception_v3.input,pooling_output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzZu5f_OM1MK"
      },
      "source": [
        "current_path=None\n",
        "all_features=[]\n",
        "\n",
        "for img, batch_paths in tqdm.tqdm(dataset):\n",
        "  batch_features=feature_extraction_model(img)\n",
        "  batch_features=tf.reshape(batch_features,\n",
        "                            (batch_features.shape[0],-1))\n",
        "  for features , path in zip(batch_features.numpy(),batch_paths.numpy()):\n",
        "    if path != current_path and current_path is not None:\n",
        "      output_path=current_path.decode().replace('.avi','.npy')\n",
        "      np.save( output_path,all_features)\n",
        "      all_features=[]\n",
        "\n",
        "    current_path=path\n",
        "    all_features.append(features)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14XJQa2iM4sH",
        "outputId": "186108f6-3ef0-4c77-85f5-ca89fa82f4a7"
      },
      "source": [
        "import glob\n",
        "LABLES=glob.glob(\"drive/MyDrive/data/train/*\")\n",
        "LABLES = [LABLES[i].split('/')[4] for i in range(len(LABLES))]\n",
        "LABLES = sorted(LABLES)\n",
        "print(len(LABLES))\n",
        "encoder=LabelBinarizer()\n",
        "encoder.fit(LABLES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbmqJs5sM_U6"
      },
      "source": [
        "model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Masking(mask_value=0.),\n",
        "    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(len(LABLES),activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkf8N6YKNB1-"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy' , 'top_k_categorical_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHd58kcDNFc5"
      },
      "source": [
        "test_file=\"drive/MyDrive/data/ucfTrainTestlist/testlist01.txt\"\n",
        "train_file=\"drive/MyDrive/data/ucfTrainTestlist/trainlist01.txt\"\n",
        "with open(test_file) as f:\n",
        "  test_list=[row.strip() for row in list(f)]\n",
        "with open(train_file) as f:\n",
        "  train_list=[row.strip() for row in list(f)]\n",
        "  train_list=[row.split(' ')[0] for row in train_list]\n",
        "  \n",
        "def make_generator(file_list):\n",
        "  def generator():\n",
        "    np.random.shuffle(file_list)\n",
        "    for path in file_list:\n",
        "      full_path=os.path.join(BASE_PATH,path).replace('.avi','.npy')\n",
        "\n",
        "      label=os.path.basename(os.path.dirname(path))\n",
        "      features=np.load(full_path)\n",
        "\n",
        "      padded_sequence=np.zeros((SEQUENCE_LENGTH,2048))\n",
        "      padded_sequence[0:len(features)]=np.array(features)\n",
        "\n",
        "      transformed_label=encoder.transform([label])\n",
        "      yield padded_sequence, transformed_label[0]\n",
        "  return generator\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhd4YZIHNIkM",
        "outputId": "4400665b-df1e-44d2-9031-330a5f038c20"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(make_generator(train_list),\n",
        "                 output_types=(tf.float32, tf.int16),\n",
        "                 output_shapes=((SEQUENCE_LENGTH, 2048), 101))\n",
        "train_dataset = train_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "valid_dataset = tf.data.Dataset.from_generator(make_generator(test_list),\n",
        "                 output_types=(tf.float32, tf.int16),\n",
        "                 output_shapes=((SEQUENCE_LENGTH, 2048), 101))\n",
        "valid_dataset = valid_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "print(train_dataset)\n",
        "print(valid_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((None, 40, 2048), (None, 101)), types: (tf.float32, tf.int16)>\n",
            "<PrefetchDataset shapes: ((None, 40, 2048), (None, 101)), types: (tf.float32, tf.int16)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsMvR3QxNSU6",
        "outputId": "8fc3d077-6dda-401d-e15e-92a7e4dcfdda"
      },
      "source": [
        "tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir='drive/MyDrive/data/models', update_freq=1000)\n",
        "model.fit(train_dataset,epochs=15,callbacks=[tensorboard_callback],validation_data=valid_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "597/597 [==============================] - 3271s 5s/step - loss: 3.4913 - accuracy: 0.1896 - top_k_categorical_accuracy: 0.4019 - val_loss: 2.6189 - val_accuracy: 0.3249 - val_top_k_categorical_accuracy: 0.6606\n",
            "Epoch 2/15\n",
            "597/597 [==============================] - 318s 532ms/step - loss: 1.9509 - accuracy: 0.4688 - top_k_categorical_accuracy: 0.7650 - val_loss: 1.5665 - val_accuracy: 0.5752 - val_top_k_categorical_accuracy: 0.8372\n",
            "Epoch 3/15\n",
            "597/597 [==============================] - 318s 532ms/step - loss: 1.3883 - accuracy: 0.6022 - top_k_categorical_accuracy: 0.8708 - val_loss: 1.6973 - val_accuracy: 0.5432 - val_top_k_categorical_accuracy: 0.8091\n",
            "Epoch 4/15\n",
            "597/597 [==============================] - 291s 488ms/step - loss: 1.0744 - accuracy: 0.6881 - top_k_categorical_accuracy: 0.9180 - val_loss: 1.4011 - val_accuracy: 0.6130 - val_top_k_categorical_accuracy: 0.8810\n",
            "Epoch 5/15\n",
            "597/597 [==============================] - 282s 472ms/step - loss: 0.8963 - accuracy: 0.7318 - top_k_categorical_accuracy: 0.9401 - val_loss: 1.2310 - val_accuracy: 0.6701 - val_top_k_categorical_accuracy: 0.8911\n",
            "Epoch 6/15\n",
            "597/597 [==============================] - 296s 496ms/step - loss: 0.7906 - accuracy: 0.7620 - top_k_categorical_accuracy: 0.9517 - val_loss: 1.3702 - val_accuracy: 0.6585 - val_top_k_categorical_accuracy: 0.8874\n",
            "Epoch 7/15\n",
            "597/597 [==============================] - 278s 466ms/step - loss: 0.6747 - accuracy: 0.7949 - top_k_categorical_accuracy: 0.9661 - val_loss: 1.2107 - val_accuracy: 0.6920 - val_top_k_categorical_accuracy: 0.8993\n",
            "Epoch 8/15\n",
            "597/597 [==============================] - 292s 490ms/step - loss: 0.5928 - accuracy: 0.8208 - top_k_categorical_accuracy: 0.9728 - val_loss: 1.2824 - val_accuracy: 0.6812 - val_top_k_categorical_accuracy: 0.8958\n",
            "Epoch 9/15\n",
            "597/597 [==============================] - 291s 487ms/step - loss: 0.5163 - accuracy: 0.8460 - top_k_categorical_accuracy: 0.9805 - val_loss: 1.3175 - val_accuracy: 0.6815 - val_top_k_categorical_accuracy: 0.9056\n",
            "Epoch 10/15\n",
            "597/597 [==============================] - 282s 472ms/step - loss: 0.4659 - accuracy: 0.8598 - top_k_categorical_accuracy: 0.9809 - val_loss: 1.6500 - val_accuracy: 0.6788 - val_top_k_categorical_accuracy: 0.8813\n",
            "Epoch 11/15\n",
            "597/597 [==============================] - 277s 463ms/step - loss: 0.4339 - accuracy: 0.8708 - top_k_categorical_accuracy: 0.9855 - val_loss: 1.5177 - val_accuracy: 0.6762 - val_top_k_categorical_accuracy: 0.8921\n",
            "Epoch 12/15\n",
            "597/597 [==============================] - 254s 426ms/step - loss: 0.3792 - accuracy: 0.8832 - top_k_categorical_accuracy: 0.9877 - val_loss: 2.3031 - val_accuracy: 0.6193 - val_top_k_categorical_accuracy: 0.8427\n",
            "Epoch 13/15\n",
            "597/597 [==============================] - 254s 425ms/step - loss: 0.3691 - accuracy: 0.8886 - top_k_categorical_accuracy: 0.9888 - val_loss: 1.6730 - val_accuracy: 0.6553 - val_top_k_categorical_accuracy: 0.8784\n",
            "Epoch 14/15\n",
            "597/597 [==============================] - 252s 422ms/step - loss: 0.3647 - accuracy: 0.8942 - top_k_categorical_accuracy: 0.9891 - val_loss: 1.5763 - val_accuracy: 0.6701 - val_top_k_categorical_accuracy: 0.8816\n",
            "Epoch 15/15\n",
            "597/597 [==============================] - 256s 429ms/step - loss: 0.3372 - accuracy: 0.9054 - top_k_categorical_accuracy: 0.9918 - val_loss: 1.8923 - val_accuracy: 0.6659 - val_top_k_categorical_accuracy: 0.8734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f16ed2e32d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLrR9GbuPlns"
      },
      "source": [
        "path = 'drive/MyDrive/data/test'\n",
        "model_file = os.path.join(path, 'my_model.hdf5')\n",
        "model.save(model_file) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}